{"title":"Komplement till Slides i Statistik","markdown":{"yaml":{"title":"Komplement till Slides i Statistik","format":"html","editor":"visual"},"headingText":"Föreläsning 3","containsRefs":false,"markdown":"\n\n\n## Ju starkare effekten är, desto större blir testets styrka\n\nDet står på sidan 23 av sliden till föreläsning 3 att ju starkare effekten är, desto större blir testets styrka. Om vi testar \\begin{eqnarray*}\n\\text{H0: det finns ingen skillnad}\n\\end{eqnarray*} innebär det att strykan är större om skillnaden är större. Vi kan genomföra en simuleringsstudie för att bevisa detta. Till exempel, jag vill testar \\begin{eqnarray*}\n\\text{H0: det finns ingen skillnad mellan väntevärdena av två oberoende grupper}\n\\end{eqnarray*} mot \\begin{eqnarray*}\n\\text{H1: det finns en skillnad mellan väntevärdena.}\n\\end{eqnarray*} Jag simulerar $n=100$ observationer från slumpvariabeln $X \\sim N(0, 1)$ och $n=100$ observationer från slumpvariabeln $Y \\sim N(\\mu, 1)$. Skillnaden i väntevärde mellan grupperna är \\begin{eqnarray*}\n\\text{E}(X) - \\text{E}(Y) & = & -\\mu.\n\\end{eqnarray*} T-testet kan används för att testa skillnaden. Jag jämför p-värdet med signifikansnivå 0.05. Jag kan upprepa simuleringen $10 000$ gånger. Resultatet sparas i vektorn `Signifikant`. Om $\\text{Signifikant[i]}=1$ innebär att den i:e simuleringen ledar till ett signifikant resultat (p-värdet \\< 0.05). Annars $\\text{Signifikant[i]}=0$.\n\n```{r, echo = FALSE, eval = TRUE}\nset.seed(12345)\n```\n\n```{r}\nMu <- 0.1 # Väntevärdet av Y\nSignifikant <- numeric(10000)\nfor(i in 1 : 10000){\n    ## Simulera X och Y\n    X <- rnorm(n = 100, mean = 0, sd = 1)\n    Y <- rnorm(n = 100, mean = Mu, sd = 1)\n    ## Genomföra t test \n    test <- t.test(X, Y)\n    ## Obtain p-value\n    Pvalue <- test$p.value\n    ## Jämföra p-värdet med signifikansnivå 0.05\n    Signifikant[i] <- (Pvalue <= 0.05)\n}\n```\n\nStyrkan hos ett statistiskt hypotestest är sannolikheten att förkasta H0 om H1 är sann. I exempelet ovan är H1 sann eftersom $\\mu = 0.1$, alltså det finns en skillnad mellan grupperna. Vi kan därför uppskatta styrkan genom `mean(Signifikant)`, dvs andelen signifikanta resultat i vår simulering:\n\n```{r}\nmean(Signifikant)\n```\n\nNu ökar jag $\\mu=0.1$ till $\\mu=0.25$ och genomför simuleringen igen.\n\n```{r, echo = FALSE, eval = TRUE}\nset.seed(12345)\n```\n\n```{r}\nMu <- 0.25 # Väntevärdet av Y\nSignifikant <- numeric(10000)\nfor(i in 1 : 10000){\n    ## Simulera X och Y\n    X <- rnorm(n = 100, mean = 0, sd = 1)\n    Y <- rnorm(n = 100, mean = Mu, sd = 1)\n    ## Genomföra t test \n    test <- t.test(X, Y)\n    ## Obtain p-value\n    Pvalue <- test$p.value\n    ## Jämföra p-värdet med signifikansnivå 0.05\n    Signifikant[i] <- (Pvalue <= 0.05)\n}\n```\n\nSkattningen av strykan blir\n\n```{r}\nmean(Signifikant)\n```\n\nvilket är större än strykan när $\\mu = 0.1$.\n\nOm jag ökar $\\mu=$ till $\\mu=1$ skulle jag får en ännu större styrka. Vi kan kolla om det stämmer.\n\n```{r, echo = FALSE, eval = TRUE}\nset.seed(12345)\n```\n\n```{r}\nMu <- 1 # Väntevärdet av Y\nSignifikant <- numeric(10000)\nfor(i in 1 : 10000){\n    ## Simulera X och Y\n    X <- rnorm(n = 100, mean = 0, sd = 1)\n    Y <- rnorm(n = 100, mean = Mu, sd = 1)\n    ## Genomföra t test \n    test <- t.test(X, Y)\n    ## Obtain p-value\n    Pvalue <- test$p.value\n    ## Jämföra p-värdet med signifikansnivå 0.05\n    Signifikant[i] <- (Pvalue <= 0.05)\n}\n```\n\nSkattningen av strykan blir\n\n```{r}\nmean(Signifikant)\n```\n\nVi kan nästan alltid upptäcka en skillnad mellan grupperna!\n\n# Föreläsning 4\n\nJag kommer att förklara hur man beräknar p-värdet för t-testet här. Ta vikten hos adeliepinviner som exempel.\n\n```{r}\nlibrary(palmerpenguins)\nAdelie <- subset(penguins, species == \"Adelie\")\nvikt <- na.omit(Adelie$body_mass_g)\n```\n\nAnta att signifikansnivån är $\\alpha = 0.05$.\n\n## H0: $\\mu = 3800 \\text{gram}$ mot H1: $\\mu \\neq 3800 \\text{gram}$\n\nVi börjar med att testa H0: $\\mu = 3800 \\text{gram}$ mot H1: $\\mu \\neq 3800 \\text{gram}$. Den standardiserade differensen mellan medelvikt och 3800 gram är \\begin{eqnarray}\nt & = & \\frac{\\bar{x} - 3800}{s / \\sqrt{n}},\n\\end{eqnarray} där $\\bar{x}$ är medelvikt som vi beräknar från data, och $s / \\sqrt{n}$ är standardfel. Sådan standardiserad differens mäter skillnaden mellan data och vår H0.\n\n-   Om $t$ är mycket större än 0 innebär att vår data tyder på att medelvikten är större än H0.\n-   Om $t$ är mycket mindre än 0 innebär att vår data tyder på att medelvikten är mindre än H0.\n\nNär vi använder `t.test()` för att testa H0 mot H1 ovan får vi resultatet\n\n```{r}\nt.test(vikt, mu = 3800)\n```\n\n$t = -2.662$ är den standardiserade skillnaden som vi kan beräkna från vår data. Vi måste bestämma om detta t-värde avviker tillräckligt från H0. Om data är normalfördelade och H0 stämmer följer $t$ en t-fördelning med frihetsgrader $n - 1$. Det betyder att $100(1 - \\alpha)%$ av alla studier skulle ge $-t_{\\alpha/2}^{(n-1)} < t < t_{\\alpha/2}^{(n-1)}$ om vi kan upprepa samma studie många gånger. I vårt exempel är frihetsgraderna 150 (eftersom vi har $151$ observationer) och $t_{\\alpha/2}^{(n-1)} = 1.975799$:\n\n```{r}\nqt(p = 1 - 0.05 / 2, df = 151 - 1)\n```\n\nDet innebär att ett t-värde som ligger mellan $-1.975905$ och $1.975905$ anses vara helt \"normalt\" om H0 är sann. Om t-värdet ligger utanför $(-1.975905, 1.975905)$ anses vår data \"konstiga\" under H0. Det vill säga, om absolutbeloppet av $t$ är stort tyder det på att H0 inte stämmer. P-värdet defineras som sannolikheten att få ett resultat som är \"minst lika extremt\" som det observerade, om H0 är sann. I vårt exempel betyder \"minst lika extremt\" att absolutbeloppet av den standardiserade differensen $t = \\frac{\\bar{x} - 3800}{s / \\sqrt{n}}$ är större eller lika med absolutebeloppet av $t = -2.662$, t-värdet som vi beräknar från data. Därför beräknar vi p-värdet som \\begin{eqnarray}\nP\\left( \\left| \\frac{\\bar{x} - 3800}{s / \\sqrt{n}} \\right| \\geq \\left| -2.662 \\right| \\right) & = & P\\left( \\frac{\\bar{x} - 3800}{s / \\sqrt{n}} \\leq -2.662 \\right) + P\\left( \\frac{\\bar{x} - 3800}{s / \\sqrt{n}} \\geq 2.662 \\right)\n\\end{eqnarray}\n\n```{r}\npt(q = -2.662, df = 151 - 1) + \n    (1 - pt(q = 2.662, df = 151 - 1))\n```\n\nP-värdet avviker lite eftersom R använder fler decimaler för $t$.\n\nJag kan rita täthetsfunktionen av t-fördelningen. P-värdet är egentligen den röda ytan under kurvan. Den blåa ytan motsvarar en \"normal\" standardiserade differens.\n\n```{r, echo = FALSE}\nf <- function(x) dt(x, df = 151 - 1)\npar(mar = c(4.1, 4.1, 1, 1))\ncurve(f, -3, 3, xlab = \"x\", ylab = \"f(x)\") \nx <- qt(seq(0.0001, 0.9999, length.out = 10000), df = 151 - 1) \nx <- c(-1.975905, x[which(x >= -1.975905 & x <= 1.975905)], 1.975905)\ny <- c(0, dt(x, df = 151 - 1), 0) \nx <- c(-1.975905, x, 1.975905)\npolygon(x = x, y = y, density = NULL, angle = 45, border = NULL, col = \"lightblue\") \nx <- seq(-4, -2.662, length.out = 100)\ny <- c(0, dt(x, df = 151 - 1)) \nx <- c(-2.662, x)\npolygon(x = x, y = y, density = NULL, angle = 45, border = NULL, col = \"red\") \nx <- seq(2.662, 4, length.out = 100)\ny <- c(dt(x, df = 151 - 1), 0) \nx <- c(x, 2.662)\npolygon(x = x, y = y, density = NULL, angle = 45, border = NULL, col = \"red\") \n```\n\nFrån resultatet av `t.test()` står det att \"95 percent confidence interval: 3626.926, 3774.398\". Det betyder att $95\\%$ konfidensintervallet för medelviken $\\mu$ är $3626.926 < \\mu < 3774.398$. Nullhypotesen är H0: $\\mu = 3800$. Om sådan $3800$ ingår i konfidensintevallet tyder på att H0 stämmer vid 5% signifikansnivå. Annars förkastar vi H0.\n\nVi kan även ser resultatet \"sample estimates: mean of x 3700.662\" från `t.test()`. Det betyder medelvärdet av våra data är 3700.662:\n\n```{r}\nmean(vikt)\n```\n\nDu får inte jämföra medelvärdet med konfidensintervallet för att bestämma om H0 stämmer. Värför det? Stickprovs medelvärde ligger alltid i konfidensintervallet! För att testa H0 använder vi det antagna värdet i H0, dvs 3800 i vårt exempel.\n\n## H0: $\\mu \\leq 3800 \\text{gram}$ mot H1: $\\mu > 3800 \\text{gram}$\n\nNu ändrar vi H0 till ensidighypotesen H0: $\\mu \\leq 3800 \\text{gram}$. Den standardiserade differensen mellan medelvikt och 3800 gram är forfarande \\begin{eqnarray}\nt & = & \\frac{\\bar{x} - 3800}{s / \\sqrt{n}}.\n\\end{eqnarray}\n\n-   Om $t$ är mycket större än 0 innebär att vår data tyder på att medelvikten är större än 3800, den antagna värdet i H0.\n-   Om $t$ är mycket mindre än 0 innebär att vår data tyder på att medelvikten är mindre än 3800.\n\nNär vi använder `t.test()` för att testa H0 mot H1 ovan får vi resultatet\n\n```{r}\nt.test(vikt, mu = 3800, alternative = \"greater\")\n```\n\n$100(1 - \\alpha)%$ av alla studier skulle ge $t < t_{\\alpha}^{(n-1)}$ om vi kan upprepa samma studie många gånger. I vårt exempel är frihetsgraderna 150 (eftersom vi har $151$ observationer) och $t_{\\alpha}^{(n-1)} = 1.655076$:\n\n```{r}\nqt(p = 1 - 0.05, df = 151 - 1)\n```\n\nDet innebär att ett t-värde som ligger mellan $-Inf$ och $1.655076$ anses vara helt \"normalt\" om H0 är sann. Om t-värdet ligger utanför $(-Inf, 1.655076)$ anses våra data \"konstiga\" under H0. Det vill säga, om $t$ är stort tyder det på att H0 inte stämmer. I vårt exempel betyder \"minst lika extremt\" att den standardiserade differensen $t = \\frac{\\bar{x} - 3800}{s / \\sqrt{n}}$ är större eller lika med $t = -2.662$, t-värdet som vi beräknar från data. Därför beräknar vi p-värdet som \\begin{eqnarray}\nP\\left( \\frac{\\bar{x} - 3800}{s / \\sqrt{n}} \\geq -2.662 \\right) &\n\\end{eqnarray}\n\n```{r}\n1 - pt(q = -2.662, df = 151 - 1)\n```\n\nP-värdet avviker lite eftersom R använder fler decimaler för $t$.\n\nJag kan rita täthetsfunktionen av t-fördelningen. P-värdet är egentligen den röda ytan under kurvan. Den blåa ytan motsvarar en \"normal\" standardiserade differens.\n\n```{r, echo = FALSE}\nf <- function(x) dt(x, df = 151 - 1)\npar(mar = c(4.1, 4.1, 1, 1), mfrow = c(1, 2))\ncurve(f, -3, 3, xlab = \"x\", ylab = \"f(x)\") \nx <- seq(-4, 1.655076, length.out = 10000)\ny <- c(dt(x, df = 151 - 1), 0) \nx <- c(x, 1.655076)\npolygon(x = x, y = y, density = NULL, angle = 45, border = NULL, col = \"lightblue\") \ncurve(f, -3, 3, xlab = \"x\", ylab = \"f(x)\") \nx <- seq(-2.662, 4, length.out = 100)\ny <- c(0, dt(x, df = 151 - 1)) \nx <- c(-2.662, x)\npolygon(x = x, y = y, density = NULL, angle = 45, border = NULL, col = \"red\") \n```\n\nFrån resultatet av `t.test()` står det att \"95 percent confidence interval: 3638.899 Inf\". Det betyder att $95\\%$ konfidensintervallet för medelviken $\\mu$ är $\\mu > 3638.899$. Nullhypotesen är H0: $\\mu = 3800$. Om sådan $3800$ ingår i konfidensintevallet tyder på att H0 stämmer vid 5% signifikansnivå. Annars förkastar vi H0.\n\nVi kan även ser resultatet \"sample estimates: mean of x 3700.662\" från `t.test()`. Det betyder medelvärdet av våra data är 3700.662:\n\n```{r}\nmean(vikt)\n```\n\nDu får inte jämföra medelvärdet med konfidensintervallet för att bestämma om H0 stämmer. Värför det? Stickprovs medelvärde ligger alltid i konfidensintervallet! För att testa H0 använder vi det antagna värdet i H0, dvs 3800 i vårt exempel.\n\n## H0: $\\mu \\geq 3800 \\text{gram}$ mot H1: $\\mu < 3800 \\text{gram}$\n\nNu ändrar vi H0 till ensidighypotesen H0: $\\mu \\geq 3800 \\text{gram}$. Den standardiserade differensen mellan medelvikt och 3800 gram är forfarande \\begin{eqnarray}\nt & = & \\frac{\\bar{x} - 3800}{s / \\sqrt{n}}.\n\\end{eqnarray}\n\n-   Om $t$ är mycket större än 0 innebär att vår data tyder på att medelvikten är större än 3800, den antagna värdet i H0.\n-   Om $t$ är mycket mindre än 0 innebär att vår data tyder på att medelvikten är mindre än 3800.\n\nNär vi använder `t.test()` för att testa H0 mot H1 ovan får vi resultatet\n\n```{r}\nt.test(vikt, mu = 3800, alternative = \"less\")\n```\n\n$100(1 - \\alpha)%$ av alla studier skulle ge $t > t_{1 - \\alpha}^{(n-1)}$ om vi kan upprepa samma studie många gånger. I vårt exempel är frihetsgraderna 150 (eftersom vi har $151$ observationer) och $t_{1 - \\alpha}^{(n-1)} = -1.655076$:\n\n```{r}\nqt(p = 0.05, df = 151 - 1)\n```\n\nDet innebär att ett t-värde som ligger mellan $-1.655076$ och Inf anses vara helt \"normalt\" om H0 är sann. Om t-värdet ligger utanför $(-1.655076, Inf)$ anses våra data \"konstiga\" under H0. Det vill säga, om $t$ är stort tyder det på att H0 inte stämmer. I vårt exempel betyder \"minst lika extremt\" att den standardiserade differensen $t = \\frac{\\bar{x} - 3800}{s / \\sqrt{n}}$ är mindre eller lika med $t = -2.662$, t-värdet som vi beräknar från data. Därför beräknar vi p-värdet som \\begin{eqnarray}\nP\\left( \\frac{\\bar{x} - 3800}{s / \\sqrt{n}} \\leq -2.662 \\right) &\n\\end{eqnarray}\n\n```{r}\npt(q = -2.662, df = 151 - 1)\n```\n\nP-värdet avviker lite eftersom R använder fler decimaler för $t$.\n\nJag kan rita täthetsfunktionen av t-fördelningen. P-värdet är egentligen den röda ytan under kurvan. Den blåa ytan motsvarar en \"normal\" standardiserade differens.\n\n```{r, echo = FALSE}\nf <- function(x) dt(x, df = 151 - 1)\npar(mar = c(4.1, 4.1, 1, 1))\ncurve(f, -3, 3, xlab = \"x\", ylab = \"f(x)\") \nx <- seq(-1.655076, 4, length.out = 10000)\ny <- c(0, dt(x, df = 151 - 1)) \nx <- c(-1.655076, x)\npolygon(x = x, y = y, density = NULL, angle = 45, border = NULL, col = \"lightblue\") \nx <- seq(-4, -2.662, length.out = 100)\ny <- c(0, dt(x, df = 151 - 1)) \nx <- c(-2.662, x)\npolygon(x = x, y = y, density = NULL, angle = 45, border = NULL, col = \"red\") \n```\n\nFrån resultatet av `t.test()` står det att \"95 percent confidence interval: -Inf 3762.426\". Det betyder att $95\\%$ konfidensintervallet för medelviken $\\mu$ är $\\mu < 3762.426$. Nullhypotesen är H0: $\\mu = 3800$. Om sådan $3800$ ingår i konfidensintevallet tyder på att H0 stämmer vid 5% signifikansnivå. Annars förkastar vi H0.\n\nVi kan även ser resultatet \"sample estimates: mean of x 3700.662\" från `t.test()`. Det betyder medelvärdet av våra data är 3700.662:\n\n```{r}\nmean(vikt)\n```\n\nDu får inte jämföra medelvärdet med konfidensintervallet för att bestämma om H0 stämmer. Värför det? Stickprovs medelvärde ligger alltid i konfidensintervallet! För att testa H0 använder vi det antagna värdet i H0, dvs 3800 i vårt exempel.\n\n# Föreläsning 7\nDet är svårt att tolka vad `wilcox.test()` egentligen testar. Vi börjar med <span style=\"color: blue;\">tvåsticksprovs Wilcoxon test (Mann-Whitney test)</span> som testar\n\\begin{eqnarray}\nH_{0}:\\quad & P\\left(X>Y\\right) = P\\left(X<Y\\right)\\\\\nH_{1}:\\quad & P\\left(X>Y\\right) \\neq P\\left(X<Y\\right)\n\\end{eqnarray}\n\n- H0 stämmer om $X$ och $Y$ följer samma fördelning. Därför kan vi dra slutsatsen att det finns någon skillnad mellan fördelningarna av $X$ och $Y$ när vi förkastar H0. Men vi vet inte vad som orsakar sådan skillnad. \n- Vilken slutsats kan vi dra om vi inte kan förkasta H0? Man kan säga att det inte finns någon tendens att $X$ tenderar vara större eller mindre än $Y$. Har de samma median? Vi vet inte.\n\nNu antar vi att fördelningarna av $X$ och $Y$ är symmetriska. Då blir\n\\begin{eqnarray}\nP\\left(X>Y\\right) = P\\left(X<Y\\right)\n\\end{eqnarray}\noch\n\\begin{eqnarray}\nX\\text{ och } Y \\text{ har samma median}\n\\end{eqnarray} \nsamma! Som följd kan vi drar följande slutsatser.\n\n- $X$ och $Y$ har samma median när vi inte förkastar H0.\n- $X$ och $Y$ har olika medianer när vi förkastar H0.\n\nMen har de samma fördelning? Vi vet inte. Det kanske finns någon skillnad mellan $X$ och $Y$, men de har samma median.\n\nVad sägs om <span style=\"color: blue;\">ensticksprovs Wilcoxon test</span> eller <span style=\"color: blue;\">Wilcoxon test med stickprov i par</span>? De testar pseudomedian! Om $X$ och $Y$ följer samma fördelning är pseudomedian medianen av fördelningen av $(X + Y) /2$. Till exempel, om $X$ följer exponetialfördelning med $\\lambda = 1$ blir $X+Y$ [gamma-fördelade](https://sv.wikipedia.org/wiki/Gammaf%C3%B6rdelning) (Gammafördelning ingår inte i kursen). Vi kan simulera en stor mängd data för att skatta pseudomedian och median. Vi simulerar $X$ och $Y$ från $\\text{Exp}(1)$, och beräknar $Z = (X + Y) /2$.\n```{r, eval = FALSE}\nz <- numeric(1e06)\nfor(i in 1 : 1e06){\n    x <- rexp(n = 1, rate = 1)\n    y <- rexp(n = 1, rate = 1)\n    z[i] <- (x + y) / 2\n}\n```\nPseudomedianen är median av $Z$ som\n```{r, eval = FALSE}\nmedian(z)\n```\nPseudomedian av $X \\sim \\text{Exp}(1)$ är `r qgamma(p = 0.5, shape = 2, rate = 1) / 2`, medan medianen av $X\\sim \\text{Exp}(1)$ är `r log(2)`.\n\nNu vet vi att det är viktigt att fördelningen är symmetrisk. Ser följande histogrammen symmetriska?\n```{r, fig.height = 3, echo = FALSE}\npar(mfrow = c(1, 3))\nn <- 2000\nNB <- 20\nset.seed(12345)\nx <- rnorm(n, 1, 1); hist(x, breaks = NB)\nx <- rexp(n, rate = 1); hist(x, breaks = NB)\nx <- rgamma(n, shape = 5, rate = 2); hist(x, breaks = NB)\n```\n\n- Histogrammet till vänster ser hyfsat symmetriskt ut. \n- Histogrammet i mitten ser inte symmetriskt ut. \n- Histogrammet till höger ser inte symmetriskt ut. "},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"knitr"},"render":{"keep-tex":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","toc":true,"toc-depth":3,"number-sections":true,"output-file":"Statistik.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.2.335","theme":"cosmo","title":"Komplement till Slides i Statistik","editor":"visual"},"extensions":{"book":{"multiFile":true}}}}}